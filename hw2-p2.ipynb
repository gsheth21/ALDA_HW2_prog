{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQZrNIv8DTjC"
   },
   "source": [
    "# Instructions\n",
    "\n",
    "1. Add your name and HW Group Number below.\n",
    "2. Complete each question. Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", and delete and `throw NotImplementedError()` lines.\n",
    "3. Where applicable, run the test cases *below* each question to check your work. **Note**: In addition to the test cases you can see, the instructor may run additional test cases, including using *other datasets* to validate you code.\n",
    "4. Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). You can also use the **Validate** button to run all test cases.\n",
    "5. Turn in your programming homework files on **moodle**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kDUK-Uq0DTjD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nName: Gaurav Sheth\\nHW Group Number: 6\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Name: Gaurav Sheth\n",
    "HW Group Number: 6\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuZj7PmgDTjE"
   },
   "source": [
    "# **Homework 2 Problem 2**\n",
    "\n",
    "In this workshop, you'll looking at evaluation metrics and hyperparameter turning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bqy9SzezDTjE"
   },
   "source": [
    "# 0 Loading Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "pyKUVD7IDTjE",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63dcfddfc1e4547ee86ba5afafddeff8",
     "grade": false,
     "grade_id": "cell-5edb17c9957ed27e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "from sklearn import datasets\n",
    "# Remember you have to run this cell block before continuing!\n",
    "\n",
    "# We will use this random seed throughout to make things more deterministic for testing\n",
    "random_seed = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "vR1KfGHIDTjE",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0eafb532481b23fa55395b352decfc40",
     "grade": false,
     "grade_id": "cell-2fae64f787a55e35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1 Complete Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "AlyZJ2gcDTjE",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "53b3643cf1e02b9de15d7f75cf0707bf",
     "grade": false,
     "grade_id": "cell-alsjdaskjd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.1 Loading the Data\n",
    "\n",
    "In this problem you will learn to calculate accuracy, precision, recall and f1-score for a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cC87gOeHDTjE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>639736</td>\n",
       "      <td>0</td>\n",
       "      <td>1881528306</td>\n",
       "      <td>Fri May 22 04:54:30 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ClareMacG</td>\n",
       "      <td>where is he? hmmmm he didnt even reply to me t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228095</td>\n",
       "      <td>0</td>\n",
       "      <td>1759081303</td>\n",
       "      <td>Sun May 10 18:25:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jaredhaha</td>\n",
       "      <td>family guy sucks tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>689126</td>\n",
       "      <td>0</td>\n",
       "      <td>2322274292</td>\n",
       "      <td>Wed Jun 24 22:20:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>spazzyyarn</td>\n",
       "      <td>@jesus_iscomin  I am so sorry, that sucks!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372153</td>\n",
       "      <td>0</td>\n",
       "      <td>1693569517</td>\n",
       "      <td>Sun May 03 22:59:23 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>missprettylady</td>\n",
       "      <td>goin to bed...definitly didn't study like i wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>365761</td>\n",
       "      <td>0</td>\n",
       "      <td>2244313762</td>\n",
       "      <td>Fri Jun 19 14:35:02 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jojoe777</td>\n",
       "      <td>just was at the hospital, long story made shor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>513783</td>\n",
       "      <td>4</td>\n",
       "      <td>2176538881</td>\n",
       "      <td>Mon Jun 15 04:08:22 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>desireecoake</td>\n",
       "      <td>i love to be tweeted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>136406</td>\n",
       "      <td>4</td>\n",
       "      <td>2003570557</td>\n",
       "      <td>Tue Jun 02 06:46:22 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>cjy26</td>\n",
       "      <td>@jensen_ackles: I´m from german, I have seen B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>241025</td>\n",
       "      <td>4</td>\n",
       "      <td>1833410879</td>\n",
       "      <td>Sun May 17 23:12:01 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Twitchyier</td>\n",
       "      <td>@angelnina if you and I were neighbors the who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>501275</td>\n",
       "      <td>4</td>\n",
       "      <td>1824226638</td>\n",
       "      <td>Sun May 17 00:30:54 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jessa_hugz</td>\n",
       "      <td>HAPPY BDAY BOBBY!!! (ebony)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>386464</td>\n",
       "      <td>4</td>\n",
       "      <td>1957171175</td>\n",
       "      <td>Thu May 28 23:43:08 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>BradleyJean</td>\n",
       "      <td>hello to all my new followers! &amp;amp; thanks fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  polarity          id                          date  \\\n",
       "0          639736         0  1881528306  Fri May 22 04:54:30 PDT 2009   \n",
       "1          228095         0  1759081303  Sun May 10 18:25:07 PDT 2009   \n",
       "2          689126         0  2322274292  Wed Jun 24 22:20:07 PDT 2009   \n",
       "3          372153         0  1693569517  Sun May 03 22:59:23 PDT 2009   \n",
       "4          365761         0  2244313762  Fri Jun 19 14:35:02 PDT 2009   \n",
       "...           ...       ...         ...                           ...   \n",
       "39995      513783         4  2176538881  Mon Jun 15 04:08:22 PDT 2009   \n",
       "39996      136406         4  2003570557  Tue Jun 02 06:46:22 PDT 2009   \n",
       "39997      241025         4  1833410879  Sun May 17 23:12:01 PDT 2009   \n",
       "39998      501275         4  1824226638  Sun May 17 00:30:54 PDT 2009   \n",
       "39999      386464         4  1957171175  Thu May 28 23:43:08 PDT 2009   \n",
       "\n",
       "          query            user  \\\n",
       "0      NO_QUERY       ClareMacG   \n",
       "1      NO_QUERY       jaredhaha   \n",
       "2      NO_QUERY      spazzyyarn   \n",
       "3      NO_QUERY  missprettylady   \n",
       "4      NO_QUERY        jojoe777   \n",
       "...         ...             ...   \n",
       "39995  NO_QUERY    desireecoake   \n",
       "39996  NO_QUERY           cjy26   \n",
       "39997  NO_QUERY      Twitchyier   \n",
       "39998  NO_QUERY      jessa_hugz   \n",
       "39999  NO_QUERY     BradleyJean   \n",
       "\n",
       "                                                    text  \n",
       "0      where is he? hmmmm he didnt even reply to me t...  \n",
       "1                              family guy sucks tonight   \n",
       "2             @jesus_iscomin  I am so sorry, that sucks!  \n",
       "3      goin to bed...definitly didn't study like i wa...  \n",
       "4      just was at the hospital, long story made shor...  \n",
       "...                                                  ...  \n",
       "39995                              i love to be tweeted   \n",
       "39996  @jensen_ackles: I´m from german, I have seen B...  \n",
       "39997  @angelnina if you and I were neighbors the who...  \n",
       "39998                       HAPPY BDAY BOBBY!!! (ebony)   \n",
       "39999  hello to all my new followers! &amp; thanks fo...  \n",
       "\n",
       "[40000 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "raw_data = pd.read_csv('hw2_p3.csv')\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwNbgtKfDTjE"
   },
   "source": [
    "We sample a subset of the dataset (stored as \"X\" and \"Y\") in order to avoid long running time. Now practice the train/test split function to create a training and testing dataset with the **\"random_seed\"** we defined at very beginning and the belowed **\"test_data_fraction\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "id": "ay7JjXz2DTjE",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31c53f60b9fe8210b85ac980e229bc06",
     "grade": false,
     "grade_id": "cell-cc7c5aa8554728a7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = raw_data.sample(frac = 0.3, random_state = random_seed)\n",
    "X = data[\"text\"]\n",
    "Y = data[\"polarity\"] == 4\n",
    "\n",
    "test_data_fraction = 0.2\n",
    "## TODO: Make the train/test split this time\n",
    "X_train = None\n",
    "X_test = None\n",
    "Y_train = None\n",
    "Y_test = None\n",
    "# YOUR CODE HERE\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, \n",
    "    test_size=test_data_fraction, \n",
    "    random_state=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpDbnaqnDTjE"
   },
   "source": [
    "Note that the X features contain just one attribute, a string value from the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DxoHcCFvDTjE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1911                               @JF_Kennedy  She would.\n",
       "18637           @ChesterBe I can't download the new song! \n",
       "21470    @DJTygerLilly technically 130p but come anytim...\n",
       "24912    YAY! I'm proud of my friend!  she rocks, she w...\n",
       "14877    NICE! the 3.0 jailbreak is out (mac only) too ...\n",
       "                               ...                        \n",
       "22283    i can't find rock band! what the hell am i goi...\n",
       "20734    @billyraycyrus Would you be able 2 ask Miley 2...\n",
       "4776     @rachmurrayX nothing  its depressing, i could ...\n",
       "5283                             Not in Texas anymore.... \n",
       "31180    Just been to a catexibition  my friend will pr...\n",
       "Name: text, Length: 9600, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifexKu8fDTjE"
   },
   "source": [
    "The y values are True (for polarity = 4) and False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QFWKEeyVDTjF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1911     False\n",
       "18637    False\n",
       "21470     True\n",
       "24912     True\n",
       "14877    False\n",
       "         ...  \n",
       "22283     True\n",
       "20734     True\n",
       "4776     False\n",
       "5283     False\n",
       "31180     True\n",
       "Name: polarity, Length: 9600, dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FN1aXbjzDTjF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10858                                    Is having a day! \n",
       "3072     @brimoni ahh im soo sowwyyy   i love u &amp; @...\n",
       "39679    This one was a different for me  Unusual but I...\n",
       "26976    @tongits lol I can't even look - too busy to g...\n",
       "29816    @piarincess I need to have lunch with you!  ASAP \n",
       "                               ...                        \n",
       "14717                           going bag paking in asda  \n",
       "28469    @jadb Get 100 followers a day using www.tweete...\n",
       "37185    Train tickets for Nottingham just came  Anyone...\n",
       "8450     I am do bummed out... My Internet on my laptop...\n",
       "12604    apparently, there was a gigantic Vista SP2 upd...\n",
       "Name: text, Length: 2400, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2xwbv7vmDTjF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10858    False\n",
       "3072     False\n",
       "39679     True\n",
       "26976     True\n",
       "29816     True\n",
       "         ...  \n",
       "14717    False\n",
       "28469     True\n",
       "37185     True\n",
       "8450     False\n",
       "12604    False\n",
       "Name: polarity, Length: 2400, dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "GWDJBRW9DTjF",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a32198d82fed50874864c28492a7f04",
     "grade": true,
     "grade_id": "cell-e928a8e016e1814e",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_equal(len(X_train),9600)\n",
    "np.testing.assert_equal(len(Y_test),2400)\n",
    "np.testing.assert_equal(type(X_test),pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "tvOJ-7jdDTjF",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e2b7689e0bbb1bf57d9d06a4a97a1483",
     "grade": false,
     "grade_id": "cell-307e8bfcba3ffd01",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.2 Classification Pipeline\n",
    "\n",
    "In this problem you will create a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), which is a nice tool provided by sklearn, to apply a list of transforms or model traning sequencially, pipeline class allows sticking multiple processes into a single estimator, it can be used to automate a machine learning workflow that involves multiple steps. For example:\n",
    "\n",
    "1. We need to extract our TFIDF features from the twitter data, just like we did in hw2-p2.\n",
    "2. Then we need to build a classifierusing our new TFIDF features.\n",
    "\n",
    "The advantage of putting these steps together into a pipeline, is that we can apply them repeatedly, e.g. to the training data and the test data.\n",
    "\n",
    "Additionally, for hyperparameter tuning, we often use k-fold cross validation, where we have many different training/test datasets, making the pipeline even more useful.\n",
    "\n",
    "Here is a brief example of how to use pipeline function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3pn2tDVgDTjF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Put the example in a function so we don't overwrite our variables\n",
    "def example():\n",
    "    X, y = make_classification(random_state=0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "    # Create a pipeline composed of a standard scaler, and an SVC classifier\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])\n",
    "\n",
    "    # Fit the pipeline to the training data (just like you would any other classifier)\n",
    "    # Both scaling and fitting will be performed\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Use the fitted pipeline (i.e. the fit scaler and trained classifier) to score the test data\n",
    "    # This will first scale X_test, then predict y-values for this data, and finally compute accuracy\n",
    "    accuracy = pipe.score(X_test, y_test)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "example()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "EVQBpImlDTjF",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b739aaa2c032083867a685d4374dd2f",
     "grade": false,
     "grade_id": "cell-191fb0e6eabae475",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now it is your turn to practice the pipeline function, create a pipeline including **1) tfidf vectorizer 2) KNN model (with 5 neighbors)** (You can refer back to the problem in hw2-p2). Store the pipeline object as **KNN_pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "id": "xnYwN52IDTjF",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c38295118ce0ae5e4dbf6de7ca7c5783",
     "grade": false,
     "grade_id": "cell-8a650d0c64a1d983",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "KNN_pipeline = None\n",
    "# YOUR CODE HERE\n",
    "KNN_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "DqpzV8SwDTjF",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64e2a0c02dc300968fc0c908514be0e9",
     "grade": true,
     "grade_id": "cell-9a68db6e2ce04989",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_equal(type(KNN_pipeline),sklearn.pipeline.Pipeline)\n",
    "np.testing.assert_equal(len(KNN_pipeline.named_steps),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "aXqQK5Q5DTjF",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4fc126f2b66a95684066a8e10653461a",
     "grade": false,
     "grade_id": "cell-0041e152e9275783",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's evaluate the knn pipeline, use the training set to train the pipeline and make prediction on the testing set. Compare the result with the true labels of the testing set and calculate the accuracy score. Store the accuracy in the variable **\"test_accuracy\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "id": "j3V4mcbiDTjF",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ee1f403ca2061a4b8faf9a4f5d00eb2",
     "grade": false,
     "grade_id": "cell-e4a9286f6128fcfe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.675"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "test_accuracy = None\n",
    "# YOUR CODE HERE\n",
    "# Create the KNN pipeline\n",
    "KNN_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "# Train the pipeline on the training data\n",
    "KNN_pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = KNN_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "test_accuracy = accuracy_score(Y_test, y_pred)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "WkDsFtN4DTjF",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bcc3ff9fc4978ad68b5ab66b49600e03",
     "grade": true,
     "grade_id": "cell-6c0d38b77b5989e4",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(test_accuracy,0.675)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "BrSUBSWdDTjF",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "051ec7526ea5faaa6f5e79212f8488f0",
     "grade": false,
     "grade_id": "cell-fe923f6e8300e7b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you can see from the aboved result, the test accuracy is not as good as we expected. Now let's play with some hyperparameter tuning to see whether we can achieve better results with the optimized parameters, choosing the best value for $k$.\n",
    "\n",
    "Let's take a look at the below example on hyper-parameter tuning of the **KNN_pipeline** we created previously, using the [GridSearchCV](https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html) function. The goal is to find the best value for $k$ (number of neighbors) in the KNN classifier, and we'll test the following values: [1,3,5,7,10].\n",
    "\n",
    "GridSearchCV will try each of these values, and then determine the best one by performing k-fold crossvalidation _within the training dataset_. If a value of k does well on unseen validation data, it will probably do well with test data.\n",
    "\n",
    "**HINT**: Select the best hyperparameter value only based on the training data\n",
    "\n",
    "**Note**: This may take a moment, since the GridSearch performs CV (multiple train/tests splits) with every hyperparameter value, leading to lots of model training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "EZ_f6yu9DTjF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter: {'knn__n_neighbors': 7}, CV score = 0.6791666666666667:\n",
      "The testing accuracy with the best parameter is: 0.68875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter we hope to tune.\n",
    "param_grid = {\n",
    "    \"knn__n_neighbors\": [1,3,5,7,10]\n",
    "}\n",
    "# Run the hyperparameter tuning with the training dataset, this will take a while to run.\n",
    "KNN_tuned_pipeline = GridSearchCV(KNN_pipeline, param_grid)\n",
    "KNN_tuned_pipeline.fit(X_train,Y_train)\n",
    "\n",
    "# Print out the best parameter as well as the cross-validated score of the best_estimator.\n",
    "print(\"Best parameter: {}, CV score = {}:\".format(KNN_tuned_pipeline.best_params_,KNN_tuned_pipeline.best_score_))\n",
    "\n",
    "# Now let's make prediction on the testing data with the best found parameters and check whether we can achieve higher accuracy.\n",
    "print(\"The testing accuracy with the best parameter is: {}\".format(accuracy_score(KNN_tuned_pipeline.predict(X_test), Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "h1y4JI-yDTjG",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22aefae6995f110bc51111778d1be854",
     "grade": false,
     "grade_id": "cell-a12a3bd50b8feef8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now it is your turn. Create the similar pipeline (with the TFIDF vectorizer, followed by a model) for the decision tree and adaboost classifiers. Then perform hyperparameter tuning to create a tuned version of each pipeline. Make sure to fit the pipelines with the **training data** you have -- selecting a hyperparameter using the test data gives an unfair advantage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "yTje-_dnDTjG",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7356789ce5ef7673f3d449dea7f10396",
     "grade": false,
     "grade_id": "cell-57c4979d5ad3e1be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For [decision tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html), make sure to use the **`random_seed`** we created at very beginning. For the hyperparameter tuning, use the `GridSearchCV` to select the best criterion from **{“gini”, “entropy”}**, and the best  max_depth from **[2,3,4,5]**.\n",
    "\n",
    "Make sure to:\n",
    "\n",
    "1. Create the pipeline\n",
    "2. Tune it with CV\n",
    "3. Fit it to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "id": "twFUKXRRDTjL",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a47cd4c4ec05ee410f018a0f234e4934",
     "grade": false,
     "grade_id": "cell-eef14b7d60e9a971",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                       ('dt',\n",
       "                                        DecisionTreeClassifier(random_state=25))]),\n",
       "             param_grid={'dt__criterion': ['gini', 'entropy'],\n",
       "                         'dt__max_depth': [2, 3, 4, 5]})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "DT_tuned_pipeline = None\n",
    "\n",
    "DT_param_grid = {\n",
    "    \"dt__criterion\": [], #TODO: Update this with parameter values\n",
    "    \"dt__max_depth\": [] #TODO: Update this with parameter values\n",
    "}\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Create the pipeline with TF-IDF and Decision Tree\n",
    "dt_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('dt', DecisionTreeClassifier(random_state=random_seed))\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "DT_param_grid = {\n",
    "    \"dt__criterion\": [\"gini\", \"entropy\"],\n",
    "    \"dt__max_depth\": [2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV to find the best hyperparameters\n",
    "DT_tuned_pipeline = GridSearchCV(\n",
    "    dt_pipeline,\n",
    "    DT_param_grid,\n",
    "    cv=5  # Using 5-fold cross-validation\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "DT_tuned_pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "KtxJ1U7eDTjL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter of DT: {'dt__criterion': 'gini', 'dt__max_depth': 5}, CV score = 0.5675000000000001:\n",
      "The testing accuracy with the best parameter of DT is: 0.5720833333333334\n"
     ]
    }
   ],
   "source": [
    "# Check the best hyperparameters for DecisionTree\n",
    "print(\"Best parameter of DT: {}, CV score = {}:\".format(DT_tuned_pipeline.best_params_,DT_tuned_pipeline.best_score_))\n",
    "print(\"The testing accuracy with the best parameter of DT is: {}\".format(accuracy_score(DT_tuned_pipeline.predict(X_test), Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "pmJblkACDTjL",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b18e0b70a16cb1507fb5d5c3043e10e",
     "grade": true,
     "grade_id": "cell-033489960e767421",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBTK2YLbDTjL"
   },
   "source": [
    "For [Adaboost classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html), make sure to use the **`random_seed`** we created at very beginning. For the hyperparameter tuning, use the `GridSearchCV` to select the best `n_estimators` from **[2,3,4]**, and the best  learning_rate from **[0.1,0.01,0.001]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "id": "B9oqLrHODTjM",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76caa850500718d0e2ddfd980bd79884",
     "grade": false,
     "grade_id": "cell-cb1444c7c39132bd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                       ('adaboost',\n",
       "                                        AdaBoostClassifier(random_state=25))]),\n",
       "             param_grid={'adaboost__learning_rate': [0.1, 0.01, 0.001],\n",
       "                         'adaboost__n_estimators': [2, 3, 4]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "ADABOOST_tuned_pipeline = None\n",
    "\n",
    "ADABOOST_param_grid = {\n",
    "    \"adaboost__n_estimators\": [], #TODO: Update this with parameter values\n",
    "    \"adaboost__learning_rate\": [] #TODO: Update this with parameter values\n",
    "}\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Create the AdaBoost pipeline with TFIDF vectorizer and AdaBoost classifier (using random_seed)\n",
    "adaboost_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('adaboost', AdaBoostClassifier(random_state=random_seed))\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid for AdaBoost\n",
    "ADABOOST_param_grid = {\n",
    "    \"adaboost__n_estimators\": [2, 3, 4],\n",
    "    \"adaboost__learning_rate\": [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV to find the best hyperparameters using 5-fold cross-validation\n",
    "ADABOOST_tuned_pipeline = GridSearchCV(\n",
    "    adaboost_pipeline,\n",
    "    ADABOOST_param_grid,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Fit the tuned pipeline to the training data\n",
    "ADABOOST_tuned_pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3t5oFOVEDTjM",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "abc09ea005cddda6c3108c6af5266ae3",
     "grade": false,
     "grade_id": "cell-8eb5cc4b2f14c0c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter of ADABOOST: {'adaboost__learning_rate': 0.1, 'adaboost__n_estimators': 4}, CV score = 0.5576041666666667:\n",
      "The testing accuracy with the best parameter of ADABOOST is: 0.5591666666666667\n"
     ]
    }
   ],
   "source": [
    "# Check the best hyperparameters for Adaboost\n",
    "print(\"Best parameter of ADABOOST: {}, CV score = {}:\".format(ADABOOST_tuned_pipeline.best_params_, ADABOOST_tuned_pipeline.best_score_))\n",
    "print(\"The testing accuracy with the best parameter of ADABOOST is: {}\".format(accuracy_score(ADABOOST_tuned_pipeline.predict(X_test), Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2S2wmQmYDTjM",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea4efd90e086e78147094a5867f615e5",
     "grade": true,
     "grade_id": "cell-fe2cd2577f11ddff",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "PrrBASlFDTjM",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8f0b3f41bac3b68e70ad639a29266738",
     "grade": false,
     "grade_id": "cell-0f5a6e8bccbae8b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.3 Evaluation using `classification_report`\n",
    "\n",
    "Sklearn also has a built in function called [`classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) that will give a handy summary of all the popular classification metrics. You can use this for the later questions.\n",
    "\n",
    "Below, we give an example of how to use the  function to summarize a model's performance.\n",
    "\n",
    "Precision, Recall and F1 are reported for **each class separately**. For the \"False\" row, a False is treated as the positive class. For the \"True\" row, the \"True\" is treated as the positive class. This is helpful because Precision and Recall are both sensitive to which class is considered positive. **Support** is the number of instances of both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "cVXu_aI5DTjM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.67      0.76      0.71      1209\n",
      "        True       0.71      0.62      0.66      1191\n",
      "\n",
      "    accuracy                           0.69      2400\n",
      "   macro avg       0.69      0.69      0.69      2400\n",
      "weighted avg       0.69      0.69      0.69      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Print a classification report for the KNN pipeline we created\n",
    "print(classification_report(Y_test, KNN_tuned_pipeline.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "dJO50udzDTjM",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e0b8c003135d8b81c0901f7634abc2d5",
     "grade": false,
     "grade_id": "cell-7d263728e087f5d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now complete the following functions based on the descriptions in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "id": "Y47xN2-EDTjT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "412beb00c9e1911af6bee85fa14e7c66",
     "grade": false,
     "grade_id": "cell-922f67c614238814",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.67      0.76      0.71      1209\n",
      "        True       0.71      0.62      0.66      1191\n",
      "\n",
      "    accuracy                           0.69      2400\n",
      "   macro avg       0.69      0.69      0.69      2400\n",
      "weighted avg       0.69      0.69      0.69      2400\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'False': {'precision': 0.6693548387096774,\n",
       "  'recall': 0.7551695616211745,\n",
       "  'f1-score': 0.7096774193548386,\n",
       "  'support': 1209},\n",
       " 'True': {'precision': 0.7142857142857143,\n",
       "  'recall': 0.6213266162888329,\n",
       "  'f1-score': 0.6645711719802425,\n",
       "  'support': 1191},\n",
       " 'accuracy': 0.68875,\n",
       " 'macro avg': {'precision': 0.6918202764976958,\n",
       "  'recall': 0.6882480889550038,\n",
       "  'f1-score': 0.6871242956675405,\n",
       "  'support': 2400},\n",
       " 'weighted avg': {'precision': 0.6916517857142858,\n",
       "  'recall': 0.68875,\n",
       "  'f1-score': 0.6872934440951953,\n",
       "  'support': 2400}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def predict_with_pipeline(pipeline):\n",
    "    \"\"\"\n",
    "    You will implement a pipeline to predict for test-cases that performs the following tasks:\n",
    "        1. Use the tuned pipeline to predict labels Y_predict for X_test.\n",
    "        3. return the predictions\n",
    "\n",
    "    Your inputs and outputs are as shown below:\n",
    "\n",
    "    Input:\n",
    "\n",
    "        pipeline: A classification/tuned pipeline.\n",
    "              Some example classifiers are: KNN_tuned_pipeline, DT_tuned_pipeline, ADABOOST_tuned_pipeline\n",
    "\n",
    "\n",
    "    Output:\n",
    "        predictions: Return the prediction by the classification pipeline on X_test\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    predictions = pipeline.predict(X_test)\n",
    "    return predictions\n",
    "\n",
    "def ClassificationReport(Y_test, predictions,output_dict=True):\n",
    "    \"\"\"\n",
    "    You will implement this function to outputs the predictions classification report for test-cases that performs the following tasks:\n",
    "        1. This function will take three parameters:  the Y_test, predictions on X_test using the pipeline, and output_dict for dictionary format report\n",
    "        2. You can use the sklearn's classification_report function to generate the report\n",
    "\n",
    "\n",
    "    Your inputs and outputs are as shown below:\n",
    "\n",
    "    Input:\n",
    "\n",
    "        Y_test: The labels from in the Y_test\n",
    "        predictions: predictions on X_test using the predict_with_pipeline function.\n",
    "        output_dict: To generate the report in dictionary format.\n",
    "\n",
    "    return:\n",
    "\n",
    "        classification report\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    report = classification_report(Y_test, predictions, output_dict=output_dict)\n",
    "    return report\n",
    "\n",
    "KNN_predictions = predict_with_pipeline(KNN_tuned_pipeline)\n",
    "\n",
    "# If output_dict is False, we get a human-readable\n",
    "print(ClassificationReport(Y_test, KNN_predictions,output_dict=False))\n",
    "\n",
    "# Otherwise we can get the report as an object, to get individual values from it\n",
    "ClassificationReport(Y_test, KNN_predictions,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "AcG_VNgcDTjT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "539ff4540b0c8791adf6a0e73e4b41db",
     "grade": true,
     "grade_id": "cell-35d4f3c5911b2289",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Public tests\n",
    "KNN_predictions = predict_with_pipeline(KNN_tuned_pipeline)\n",
    "KNN_report = ClassificationReport(Y_test, KNN_predictions)\n",
    "DT_predictions = predict_with_pipeline(DT_tuned_pipeline)\n",
    "ADABOOST_predictions = predict_with_pipeline(ADABOOST_tuned_pipeline)\n",
    "DT_report = ClassificationReport(Y_test, DT_predictions)\n",
    "ADABOOST_report = ClassificationReport(Y_test, ADABOOST_predictions)\n",
    "\n",
    "np.testing.assert_almost_equal(KNN_report['True']['precision'],0.7142857142857143)\n",
    "np.testing.assert_almost_equal(DT_report['False']['recall'],0.9156327543424317)\n",
    "np.testing.assert_almost_equal(ADABOOST_report['False']['f1-score'],0.6724458204334366)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "6Ohmw_HYDTjT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8823f538124e31ea8400da87fbb3f6e2",
     "grade": true,
     "grade_id": "cell-cdd265f59d583b80",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Private tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzy9z0fhDTjT"
   },
   "source": [
    "Now let's print the reports for each classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "GEy4WwYkDTjT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.67      0.76      0.71      1209\n",
      "        True       0.71      0.62      0.66      1191\n",
      "\n",
      "    accuracy                           0.69      2400\n",
      "   macro avg       0.69      0.69      0.69      2400\n",
      "weighted avg       0.69      0.69      0.69      2400\n",
      "\n",
      "\n",
      "\n",
      "Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.54      0.92      0.68      1209\n",
      "        True       0.72      0.22      0.34      1191\n",
      "\n",
      "    accuracy                           0.57      2400\n",
      "   macro avg       0.63      0.57      0.51      2400\n",
      "weighted avg       0.63      0.57      0.51      2400\n",
      "\n",
      "\n",
      "\n",
      "Adaboost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.54      0.90      0.67      1209\n",
      "        True       0.68      0.21      0.33      1191\n",
      "\n",
      "    accuracy                           0.56      2400\n",
      "   macro avg       0.61      0.56      0.50      2400\n",
      "weighted avg       0.61      0.56      0.50      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('KNN:')\n",
    "print(ClassificationReport(Y_test, KNN_predictions,output_dict=False))\n",
    "\n",
    "print('\\n')\n",
    "print('Decision Tree:')\n",
    "print(ClassificationReport(Y_test, DT_predictions,output_dict=False))\n",
    "\n",
    "print('\\n')\n",
    "print('Adaboost:')\n",
    "print(ClassificationReport(Y_test, ADABOOST_predictions,output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "nRcJXvCQDTjT",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff08922f58ae534739ac7501ba728a6c",
     "grade": false,
     "grade_id": "cell-e51c30a130bedf25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We would be most interested in the 'True' category as this indicates the positive labels, as well as the accuracy scores. Through this process, you should already got three reports for each of the classifiers. Let's make some comparisons, print the reports for each of the classifiers, and which classifier has a better performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTriM-2xDTjT"
   },
   "source": [
    "**ANSWER**\n",
    "\n",
    "If we focus on the True (positive) class and consider the overall accuracy, KNN is the best performer. It not only provides the highest accuracy (69%) but also maintains a balanced precision (0.71) and recall (0.62) for the True class, resulting in a substantially better F1-score (0.66) compared to the other classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "TU3ZxmSlDTjT",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "211088471859f4da1fba626408c9638c",
     "grade": false,
     "grade_id": "cell-0a49b9dcf85ef5d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.4 Evaluation using ROC Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "D5kCHhDfDTjT",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eaf6a5e8301880d0114f0cebd880f324",
     "grade": false,
     "grade_id": "cell-611f2cf243b3746d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Sklearn has some built in methods for [plotting ROC curves](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_roc_curve.html).\n",
    "\n",
    "The dataset we'll be using for this exercise is the breast cancer dataset, which is used to tell if a certain individal might have breast cancer or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "PfAtHC-oDTjT",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "498bd267a2012a19e4c9fed5b1c048b8",
     "grade": false,
     "grade_id": "cell-488b13155465b85e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Plotting ROC Curves\n",
    "\n",
    "In this section, you will use sklearn API to compute ROC curves and corresponding AUC value. Specifically, you can use [roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve) and [roc_auc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score) to compute these values.\n",
    "\n",
    "**Hint** You may also want to take a look at the `predict_proba` function from different models such as [decision tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.predict_proba) and [Ada boost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html). You will need to reliy on part of its output since ROC is computed based on proabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "id": "hfH4QSESDTjT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "967263475259347afb5aa7017189887b",
     "grade": false,
     "grade_id": "roc_auc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def roc_auc(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    In this function, you will need to implement the following steps.\n",
    "        1. Use model to compute its probability of predicting a sample as positive for each sample in x_test.\n",
    "        2. Use the computed probability and y_test to compute ROC curve and its AUC value.\n",
    "\n",
    "    Your inputs and outputs are as shown below:\n",
    "\n",
    "    Input:\n",
    "        model: A sklearn classifier instance in our case a fine tuned classifier. Assuming it has predict_proba() function.\n",
    "        x_test: A numpy array of shape (n_test_rows, n_attributes) where n_test_rows refers to the number\n",
    "              of rows in your target dataset and n_attributes refers to the number of attributes.\n",
    "        y_test: A numpy array of shape (n_test_rows, ) where n_test_rows refers to the number\n",
    "              of rows in your target dataset and n_attributes refers to the number of attributes.\n",
    "\n",
    "    Output:\n",
    "        fpr: A list of increasing false positive rates as a part of ROC curve.\n",
    "        tpr: A list of increasing true positive rates as a part of ROC curve.\n",
    "        thresholds: A list of decreasing thresholds as a part of ROC curve.\n",
    "        auc: A single float value that is the computed AUC value.\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # Get the probability predictions for the positive class (assumed to be at index 1)\n",
    "    probs = model.predict_proba(x_test)[:, 1]\n",
    "    \n",
    "    # Compute the ROC curve\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, probs)\n",
    "    \n",
    "    # Compute the AUC value\n",
    "    auc_value = metrics.roc_auc_score(y_test, probs)\n",
    "    \n",
    "    return fpr, tpr, thresholds, auc_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "kSQnvhmyDTjT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x250174dea30>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the ROC curves\n",
    "tree_fpr, tree_tpr, tree_thresh, tree_auc = roc_auc(DT_tuned_pipeline, X_test, Y_test)\n",
    "knn_fpr, knn_tpr, knn_thresh, knn_auc = roc_auc(KNN_tuned_pipeline, X_test, Y_test)\n",
    "ada_fpr, ada_tpr, ada_thresh, ada_auc = roc_auc(ADABOOST_tuned_pipeline, X_test, Y_test)\n",
    "\n",
    "plt.figure(0).clf()\n",
    "plt.plot(knn_fpr,knn_tpr,label=\"KNN, auc=\"+str(knn_auc))\n",
    "plt.plot(tree_fpr,tree_tpr,label=\"Decision Tree, auc=\"+str(tree_auc))\n",
    "plt.plot(ada_fpr,ada_tpr,label=\"Adaboost, auc=\"+str(ada_auc))\n",
    "\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "tL8-NEK3DTjT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9746e477fadb12c88b11e970c701714",
     "grade": true,
     "grade_id": "roc_auc_test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "np.testing.assert_almost_equal(tree_fpr, [0.         ,0.00330852, 0.00661704, 0.08436725, 0.83953681, 0.84946237,\n",
    " 0.88585608, 0.88585608, 0.89330025, 0.89578164, 0.92886683, 0.95947064,\n",
    " 0.96691481, 0.99917287, 1.        ])\n",
    "np.testing.assert_almost_equal(tree_tpr, [0.00000000e+00, 8.39630563e-04, 2.51889169e-02, 2.23341730e-01,\n",
    " 9.42905122e-01, 9.52141058e-01, 9.75650714e-01, 9.77329975e-01,\n",
    " 9.79009236e-01, 9.83207389e-01, 9.92443325e-01, 9.95801847e-01,\n",
    " 9.98320739e-01, 9.98320739e-01, 1.00000000e+00])\n",
    "np.testing.assert_almost_equal(tree_thresh, [2.,         1.,         0.91208791, 0.73289902, 0.49504405, 0.42857143,\n",
    " 0.29588015, 0.25,       0.16363636, 0.14814815, 0.11724138, 0.08823529,\n",
    " 0.0625,     0.02054795, 0.        ])\n",
    "assert tree_auc == 0.6078227316953244\n",
    "\n",
    "np.testing.assert_almost_equal(ada_fpr, [0.,         0.09263854, 0.10173697, 0.89081886, 0.9611249,  0.96526055,\n",
    " 0.96691481, 0.99834574, 1.        ])\n",
    "np.testing.assert_almost_equal(ada_tpr, [0.,         0.20486986, 0.21494542, 0.96641478, 0.99916037, 1.,\n",
    " 1.,         1.,         1.,        ])\n",
    "np.testing.assert_almost_equal(ada_thresh, [1.59082288, 0.59082288, 0.52068725, 0.49573201, 0.42515557, 0.4220354,\n",
    " 0.35457358, 0.33206415, 0.27221056])\n",
    "assert ada_auc == 0.5854634878767486\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5H3RCSd5DTjU",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3374d9c5844362a1ff9872c345837bf6",
     "grade": true,
     "grade_id": "roc_auc_test_2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Remember there are hidden tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "iCiFH2DQDTjU",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "00e365dd4e4fdeb8bc222b19b07bbe64",
     "grade": false,
     "grade_id": "cell-4c6ed5f7c66aef81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.2 Intepreting ROC curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "BkU3e1X6DTjU",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "81f7e1898f6f0200d1cc32f6e8ece1b5",
     "grade": false,
     "grade_id": "cell-9f7497f03bb03d0e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Take a look at the above ROC curves. How are they similar? How do they differ? Is one strictly better than the other? In what situations is one better than the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRgyTvN9DTjU"
   },
   "source": [
    "**ANSWER**\n",
    "\n",
    "All three ROC curves show the relationship between the true positive rate and the false positive rate across different thresholds. They all begin at (0, 0) and end at (1, 1), and each curve lies above the diagonal line that represents random guessing.\n",
    "\n",
    "They differ in shape, with some models achieving higher true positive rates for the same false positive rates. In this example, the KNN curve generally hugs the top-left corner more closely than the Decision Tree and AdaBoost curves, which indicates a better overall performance.\n",
    "\n",
    "While one model might dominate across most thresholds, a model is not strictly better unless its curve is above the others at every point. Here, KNN appears to outperform the others overall, but if the curves had crossed, the choice might depend on the specific threshold of interest.\n",
    "\n",
    "The best model depends on the application. If high sensitivity is crucial and some false positives are acceptable, a model with a higher true positive rate at lower thresholds may be preferred. Conversely, if reducing false positives is critical, a model that maintains a low false positive rate might be more appropriate, even if its overall AUC is slightly lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GkKHgfxDTjU"
   },
   "source": [
    "**Remember**: Make sure to complete all problems (.ipynb files) in this assignment. When you finish, double-check the submission instructions at the top of this file, and submit on JupyterHub."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
